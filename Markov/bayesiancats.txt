With his distinctive spotted coat and large size, the Bengal looks like a wild cat on the prowl, but although one of his ancestors is the small, wild Asian leopard cat, he’s a domestic cat through and through. Bengals take their name from the Asian leopard cat’s scientific name, Felis bengalensis. They were created through crosses between an Asian leopard cat — which in the 1950s and into the 1960s could be purchased at pet stores — and domestic shorthairs. Jean Mill, a breeder in California, was the first to make such a cross, but not because she wanted to create a new breed. She had acquired a leopard cat and allowed her to keep company with a black tom cat so she wouldn’t be lonely. To her surprise, since she hadn’t thought the two species would mate, kittens resulted, and Mill kept a spotted female. Breeding her back to her father produced a litter of spotted and solid kittens. At about the same time, Dr. Willard Centerwall was crossing Asian leopard cats with domestic cats at Loyola University. The leopard cats were resistant to the feline leukemia virus, so researchers were interested in finding out if the trait could be passed on to hybrid offspring. Various breeders became interested in developing the cats as a breed. Mill was one of them. Changes in her life had caused her to give up cat breeding, but she was ready to begin again. She had acquired some of Dr. Centerwall’s hybrids and sought out suitable males to breed to them. One was an orange domestic shorthair that she found in India, of all places, and the other was a brown spotted tabby acquired from a shelter. Bengals today are considered to be one and the same with domestic cats, and any Bengal purchased should be at least four generations removed from any ancestors with wild bloodlines.
The first cat association to recognize the Bengal was The International Cat Association, which granted the breed experimental status in 1983, followed by full recognition in 1991. The Bengal is also recognized by the American Cat Fanciers Association, the Canadian Cat Association and the United Feline Organization. Bengal cats are so sought after, that a British woman paid over $50,000 for her bengal cat in 1990, dubbing them the "Rolls Royce" of feline companions. This is a large cat. Bengals weigh 8 to 15 pounds or more. The Bengal is highly active and highly intelligent. This makes him fun to live with, but he can sometimes be challenging. On the whole, the Bengal is a confident, talkative, friendly cat who is always alert. Nothing escapes his notice. He likes to play games, including fetch, and he’s a whiz at learning tricks. His nimble paws are almost as good as hands, and it’s a good thing he doesn’t have opposable thumbs or he would probably rule the world. Bored bengal cats can also adopt some unconventional (and slightly destructive) habits, including: turning light switches on and off, fishing seals out of drains and excitedly plucking CDs from your DVD player.
Fond of playing in water, the Bengal is not above jumping into the tub or strolling into the shower with you. Aquarium and pond fish may be at risk from his clever paws. He also loves to climb and can often be found perching at the highest point he can reach in the home. A tall cat tree or two is a must for this feline, as are puzzle toys that will challenge his intelligence. On the rare occasions that he isn’t swinging on chandeliers or swimming in your pool, the affectionate Bengal will be pleased to sit on your lap. It goes without saying that he will share your bed. And yes, he steals the covers.
Both pedigreed cats and mixed-breed cats have varying incidences of health problems that may be genetic in nature. Bengals are generally healthy, but the following diseases have been seen in the breed: Distal neuropathy, a nervous system disorder that causes weakness. It can occur in Bengals as early as 1 year of age. Fortunately, many cats recover on their own, although a few relapse. Flat-chested kitten syndrome, a deformity that can range from mild to severe. Kittens who survive to adulthood usually show no signs once they reach maturity. Hip dysplasia, which in severe cases can cause lameness
Hypertrophic cardiomyopathy, a form of heart disease that is heritable in some breeds. Patellar luxation, a hereditary dislocation of the kneecap that can range from mild to severe. Severe cases can be alleviated with surgery. Progressive retinal atrophy, a degenerative eye disease. The short, thick coat of the Bengal is easily cared for with weekly combing to remove dead hair and distribute skin oils. A bath is rarely necessary. Brush the teeth to prevent periodontal disease. Daily dental hygiene is best, but weekly brushing is better than nothing. Trim the nails every couple of weeks. Wipe the corners of the eyes with a soft, damp cloth to remove any discharge. Use a separate area of the cloth for each eye so you don’t run the risk of spreading any infection. Check the ears weekly. If they look dirty, wipe them out with a cotton ball or soft damp cloth moistened with a 50-50 mixture of cider vinegar and warm water. Avoid using cotton swabs, which can damage the interior of the ear. Keep the litter box spotlessly clean. Cats are very particular about bathroom hygiene, and a dirty box may cause them to start using other places in the house instead.
It’s a good idea to keep a Bengal as an indoor-only cat to protect him from diseases spread by other cats, attacks by dogs or coyotes, and the other dangers that face cats who go outdoors, such as being hit by a car. Keeping him indoors also protects local birds and wildlife from this avid hunter. If possible, build your Bengal a large outdoor enclosure where he can jump and climb safely. Bengals who go outdoors also run the risk of being stolen by someone who would like to have such a beautiful cat without paying for it. The Bengal could never be called delicate. He is an athlete: agile and graceful with a strong, muscular body, as befits a cat who looks as if he belongs in the jungle. His broad head is a modified wedge shape, longer than it is wide, with rounded contours. Atop it are medium-size to small ears that are relatively short, set toward the side of the head. Large oval eyes are almost round. Joining the head to the body is a long, muscular neck. Supporting the body are medium-length legs, slightly longer in the back than in the front, with large, round paws. A thick, medium-length tail  tapers at the end and is tipped in black. When a Bengal rolls over, you can see that another characteristic is a spotted belly.
Enhancing the Bengal’s wild appearance is a short, thick pelt that feels luxuriously soft and silky. It comes in several colors and patterns, including brown tabby, seal mink tabby, black silver tabby, and seal silver lynx point. The coat can be spotted randomly or in horizontal patterns, or it can be marbled, with horizontal stripes arranged randomly on a lighter background. Some Bengals have a coat that is described as “glittered.” The fur shimmers in the light, as if it were tipped with gold dust. The active and social Bengal is a perfect choice for families with children and cat-friendly dogs. He will play fetch as well as any retriever, learns tricks easily and loves the attention he receives from children who treat him politely and with respect. He’s smart enough to get out of the way of toddlers but loves school-age children because they are a match for his energy level and curiosity. Nothing scares him, certainly not dogs, and he will happily make friends with them if they don’t give him any trouble. Always introduce any pets, even other cats, slowly and in a controlled setting. Like many active cats, bengals have a high prey drive and should not be trusted with smaller prey animals such as: hamsters, smaller rabbits and guinea pigs. The tiger (Panthera tigris) is the largest cat species, most recognizable for their pattern of dark vertical stripes on reddish-orange fur with a lighter underside. The species is classified in the genus Panthera with the lion, leopard, jaguar, and snow leopard. Tigers are apex predators, primarily preying on ungulates such as deer and bovids. They are territorial and generally solitary but social animals, often requiring large contiguous areas of habitat that support their prey requirements. This, coupled with the fact that they are indigenous to some of the more densely populated places on Earth, has caused significant conflicts with humans. Tigers once ranged widely across eastern Eurasia, from the Black Sea in the west, to the Indian Ocean in the south, and from Kolyma to Sumatra in the east. Over the past 100 years, they have lost 93 percent of their historic range, and have been extirpated from Western and Central Asia, from the islands of Java and Bali, and from large areas of Southeast, Southern, and Eastern Asia. Today, they range from the Siberian taiga to open grasslands and tropical mangrove swamps. The remaining six tiger subspecies have been classified as endangered by the International Union for Conservation of Nature (IUCN). The global population in the wild is estimated to number between 3,062 and 3,948 individuals, down from around 100,000 at the start of the 20th century, with most remaining populations occurring in small pockets isolated from each other, in which about 2,000 tigers live on the Indian subcontinent. A 2016 global census estimated the population of wild tigers at approximately 3,890 individuals. Major reasons for population decline include habitat destruction, habitat fragmentation and poaching. The extent of area occupied by tigers is estimated at less than 1,184,911 km2 (457,497 sq mi), a 41 percent decline from the area estimated in the mid-1990s. In 2016, the WWF declared that the world's count of wild tigers has risen for the first time in a century. Tigers are among the most recognisable and popular of the world's charismatic megafauna. They have featured prominently in ancient mythology and folklore, and continue to be depicted in modern films and literature. They appear on many flags, coats of arms, and as mascots for sporting teams. The tiger is the national animal of Bangladesh, India, Malaysia and South Korea. Tigers have muscular bodies with powerful forelimbs, large heads and long tails. The pelage is dense and heavy; colouration varies between shades of orange and brown with white ventral areas and distinctive vertical black stripes, whose patterns are unique to each individual. Their function is likely for camouflage in vegetation such as long grass with strong vertical patterns of light and shade. The tiger is one of only a few striped cat species; it is not known why spotted patterns and rosettes are the more common camouflage pattern among felids. A tiger's coat pattern is still visible when it is shaved. This is due not to skin pigmentation, but to the stubble and hair follicles embedded in the skin, similar to human beards, and is in common with other big cats. They have a mane-like heavy growth of fur around the neck and jaws and long whiskers, especially in males. The pupils are circular with yellow irises. The small, rounded ears have a prominent white spot on the back, surrounded by black. These false "eyespots", called ocelli, apparently play an important role in intraspecies communication. The skull is similar to that of the lion, though the frontal region is usually not as depressed or flattened, with a slightly longer postorbital region. The skull of a lion has broader nasal openings. However, due to variation in skulls of the two species, the structure of the lower jaw is a more reliable indicator of species. The tiger also has fairly stout teeth; the somewhat curved canines are the longest among living felids with a crown height of up to 90 mm (3.5 in). The oldest recorded captive tiger lived for 26 years. A wild specimen, having no natural predators, could in theory live to a comparable age. Bayesian statistics, named for Thomas Bayes, is a theory in the field of statistics in which the evidence about the true state of the world is expressed in terms of degrees of belief known as Bayesian probabilities. Such an interpretation is only one of a number of interpretations of probability and there are other statistical techniques that are not based on 'degrees of belief'. One of the key ideas of Bayesian statistics is that "probability is orderly opinion, and that inference from data is nothing other than the revision of such opinion in the light of relevant new information." Monte Carlo methods (or Monte Carlo experiments) are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. Their essential idea is using randomness to solve problems that might be deterministic in principle. They are often used in physical and mathematical problems and are most useful when it is difficult or impossible to use other approaches. Monte Carlo methods are mainly used in three distinct problem classes: optimization, numerical integration, and generating draws from a probability distribution. In physics-related problems, Monte Carlo methods are useful for simulating systems with many coupled degrees of freedom, such as fluids, disordered materials, strongly coupled solids, and cellular structures (see cellular Potts model, interacting particle systems, McKean-Vlasov processes, kinetic models of gases). Other examples include modeling phenomena with significant uncertainty in inputs such as the calculation of risk in business and, in math, evaluation of multidimensional definite integrals with complicated boundary conditions. In application to space and oil exploration problems, Monte Carlo–based predictions of failure, cost overruns and schedule overruns are routinely better than human intuition or alternative "soft" methods. In principle, Monte Carlo methods can be used to solve any problem having a probabilistic interpretation. By the law of large numbers, integrals described by the expected value of some random variable can be approximated by taking the empirical mean (a.k.a. the sample mean) of independent samples of the variable. When the probability distribution of the variable is parametrized, mathematicians often use a Markov chain Monte Carlo (MCMC) sampler. The central idea is to design a judicious Markov chain model with a prescribed stationary probability distribution. That is, in the limit, the samples being generated by the MCMC method will be samples from the desired (target) distribution. By the ergodic theorem, the stationary distribution is approximated by the empirical measures of the random states of the MCMC sampler. In other problems, the objective is generating draws from a sequence of probability distributions satisfying a nonlinear evolution equation. These flows of probability distributions can always be interpreted as the distributions of the random states of a Markov process whose transition probabilities depend on the distributions of the current random states (see McKean-Vlasov processes, nonlinear filtering equation). In other instances we are given a flow of probability distributions with an increasing level of sampling complexity (path spaces models with an increasing time horizon, Boltzmann-Gibbs measures associated with decreasing temperature parameters, and many others). These models can also be seen as the evolution of the law of the random states of a nonlinear Markov chain. A natural way to simulate these sophisticated nonlinear Markov processes is to sample a large number of copies of the process, replacing in the evolution equation the unknown distributions of the random states by the sampled empirical measures. In contrast with traditional Monte Carlo and MCMC methodologies these mean field particle techniques rely on sequential interacting samples. The terminology mean field reflects the fact that each of the samples (a.k.a. particles, individuals, walkers, agents, creatures, or phenotypes) interacts with the empirical measures of the process. When the size of the system tends to infinity, these random empirical measures converge to the deterministic distribution of the random states of the nonlinear Markov chain, so that the statistical interaction between particles vanishes. The main idea behind this method is that the results are computed based on repeated random sampling and statistical analysis. The Monte Carlo simulation is in fact random experimentations, in the case that, the results of these experiments are not well known. Monte Carlo simulations are typically characterized by a large number of unknown parameters, many of which are difficult to obtain experimentally. Monte Carlo simulation methods do not always require truly random numbers to be useful (although, for some applications such as primality testing, unpredictability is vital). Many of the most useful techniques use deterministic, pseudorandom sequences, making it easy to test and re-run simulations. The only quality usually necessary to make good simulations is for the pseudo-random sequence to appear "random enough" in a certain sense. What this means depends on the application, but typically they should pass a series of statistical tests. Testing that the numbers are uniformly distributed or follow another desired distribution when a large enough number of elements of the sequence are considered is one of the simplest, and most common ones. Weak correlations between successive samples is also often desirable/necessary. Bayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available. Bayesian inference is an important technique in statistics, and especially in mathematical statistics. Bayesian updating is particularly important in the dynamic analysis of a sequence of data. Bayesian inference has found application in a wide range of activities, including science, engineering, philosophy, medicine, sport, and law. In the philosophy of decision theory, Bayesian inference is closely related to subjective probability, often called Bayesian probability. If the evidence does not match up with a hypothesis, one should reject the hypothesis. But if a hypothesis is extremely unlikely a priori, one should also reject it, even if the evidence does appear to match up. The critical point about Bayesian inference, then, is that it provides a principled way of combining new evidence with prior beliefs, through the application of Bayes' rule. (Contrast this with frequentist inference, which relies only on the evidence as a whole, with no reference to prior beliefs.) Furthermore, Bayes' rule can be applied iteratively: after observing some evidence, the resulting posterior probability can then be treated as a prior probability, and a new posterior probability computed from new evidence. This allows for Bayesian principles to be applied to various kinds of evidence, whether viewed all at once or over time. This procedure is termed "Bayesian updating". Bayesian hierarchical modelling is a statistical model written in multiple levels (hierarchical form) that estimates the parameters of the posterior distribution using the Bayesian method. The sub-models combine to form the hierarchical model, and Bayes' theorem is used to integrate them with the observed data and account for all the uncertainty that is present. The result of this integration is the posterior distribution, also known as the updated probability estimate, as additional evidence on the prior distribution is acquired. Frequentist statistics, the more popular foundation of statistics, has been known to contradict Bayesian statistics due to the Bayesian treatment of the parameters as random variables and its use of subjective information in establishing assumptions on these parameters. However, Bayesians argue that relevant information regarding decision making and updating beliefs cannot be ignored and that hierarchical modeling has the potential to overrule classical methods in applications where respondents give multiple observational data. Moreover, the model has proven to be robust, with the posterior distribution less sensitive to the more flexible hierarchical priors.
Hierarchical modeling is used when information is available on several different levels of observational units. The hierarchical form of analysis and organization helps in the understanding of multiparameter problems and also plays an important role in developing computational strategies. In Bayesian statistical inference, a prior probability distribution, often simply called the prior, of an uncertain quantity is the probability distribution that would express one's beliefs about this quantity before some evidence is taken into account. For example, the prior could be the probability distribution representing the relative proportions of voters who will vote for a particular politician in a future election. The unknown quantity may be a parameter of the model or a latent variable rather than an observable variable. Bayes' theorem calculates the renormalized pointwise product of the prior and the likelihood function, to produce the posterior probability distribution, which is the conditional distribution of the uncertain quantity given the data.
Similarly, the prior probability of a random event or an uncertain proposition is the unconditional probability that is assigned before any relevant evidence is taken into account. Priors can be created using a number of methods. A prior can be determined from past information, such as previous experiments. A prior can be elicited from the purely subjective assessment of an experienced expert. An uninformative prior can be created to reflect a balance among outcomes when no information is available. Priors can also be chosen according to some principle, such as symmetry or maximizing entropy given constraints; examples are the Jeffreys prior or Bernardo's reference prior. When a family of conjugate priors exists, choosing a prior from that family simplifies calculation of the posterior distribution. Parameters of prior distributions are a kind of hyperparameter. For example, if one uses a beta distribution to model the distribution of the parameter p of a Bernoulli distribution, then p is a parameter of the underlying system (Bernoulli distribution), and
alpha and beta are parameters of the prior distribution (beta distribution), hence hyperparameters. Hyperparameters themselves may have hyperprior distributions expressing beliefs about their values. A Bayesian model with more than one level of prior like this is called a hierarchical Bayes model.
